# Quick Start: MID Filtered Documents Download

## What This Does

Downloads documents from Books 238-3971 (MID portal) for **57 specific document types** using **parallel processing** for 5-10x faster performance compared to sequential downloads.

## Document Types Included

Your filtered list includes:
- **Property Records**: Deed, Trustees Deed, Tax Deed, Transfer on Death Deed, Deed Restrictions
- **Access Rights**: Right of Way, Easement
- **Trust Documents**: Trust Agreement, Heirship, Last Will and Testament, Living Will
- **Agreements**: Agreement, Agreement-Deeds, Contract to Sell, Option
- **Covenants**: Protective Covenant, Amended Protective C, Protective Cov Termi
- **Mineral Rights**: Mineral Deed, Royalty Deed, Assign Oil Gas Min, Mineral Right Roya
- **Leases**: Lease Assignment, Assignment of Leases, Lease Contract, Amendment to Lease
- **Plats & Surveys**: Subdivision Plats, Correction of Plat, Map, Surveys
- **Legal Actions**: Judgment or Order, Eminent Domain, Sealed
- **Declarations**: Declaration, Amended Declaration, Supplement, Declaration of Road
- **Certifications**: Affidavit "T", Patent, Waiver, Cert of Saleseized, Receiver
- **Amendments**: Amendment(T), Amendment(W), Supplement to Covena
- **Special**: Miscellaneous, Miscellaneous "T", Miscellaneous "C", Environmental Protec, and more

**Total Expected**: ~200,000-250,000 documents

## Prerequisites

Ensure you have:
- [x] Ghostscript installed: `sudo apt-get install ghostscript`
- [x] GCS credentials: `export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json`
- [x] Database credentials: `source index_database/.db_credentials`
- [x] Python packages: `pip install psycopg2-binary google-cloud-storage tqdm`

## Quick Start

### Option 1: Using Shell Script (Recommended)

```bash
# Run with default settings (5 workers)
./download_mid_filtered_documents.sh

# Run with more workers for faster downloads
./download_mid_filtered_documents.sh --workers 10

# Test with dry run first
./download_mid_filtered_documents.sh --workers 3 --dry-run
```

### Option 2: Direct Python Script

```bash
cd madison_county_doc_puller

# Standard run (5 workers)
python3 parallel_staged_downloader.py --stage stage-mid-filtered --workers 5

# Faster run (10 workers)
python3 parallel_staged_downloader.py --stage stage-mid-filtered --workers 10

# Dry run test
python3 parallel_staged_downloader.py --stage stage-mid-filtered --workers 3 --dry-run
```

## What Happens

1. **Prerequisites Check**: Verifies Ghostscript, GCS credentials, database connection
2. **Statistics Display**: Shows total documents, document type breakdown
3. **Confirmation Prompt**: Asks if you want to proceed
4. **Parallel Download**: Uses 5-10 worker threads to download concurrently
5. **PDF Optimization**: Compresses each PDF by 50-70%
6. **GCS Upload**: Uploads to organized folder structure
7. **Database Tracking**: Updates status for each document
8. **Progress Display**: Real-time progress bar with statistics
9. **Final Summary**: Shows completion stats, errors, performance metrics

## Expected Performance

| Workers | Docs/Hour | Time for 200K docs |
|---------|-----------|-------------------|
| 3 | 3,000 | ~67 hours (2.8 days) |
| 5 | 4,500 | ~45 hours (1.9 days) |
| 10 | 7,500 | ~27 hours (1.1 days) |

Compare to historical sequential download: **932 docs/hour** (214 hours / 8.9 days)

**Speed Improvement**: 5-8x faster! ðŸš€

## Monitoring Progress

### During Download

The script displays:
```
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/200000 [02:30<08:15, 312.5 docs/s]
```

Watch live statistics:
- Documents completed
- Current speed (docs/hour)
- Estimated time remaining
- Success/failure rates

### Check Database

```bash
# Source credentials first
source index_database/.db_credentials

# Check progress
PGPASSWORD="$DB_PASSWORD" psql -h 127.0.0.1 -p 5432 -U "$DB_USER" -d madison_county_index -c "
SELECT
    download_status,
    COUNT(*)
FROM index_documents
WHERE book >= 238 AND book < 3972
GROUP BY download_status;
"
```

### View Logs

```bash
# Follow log in real-time
tail -f madison_county_doc_puller/parallel_staged_download.log

# Check for errors
grep -i error madison_county_doc_puller/parallel_staged_download.log

# See worker activity
grep "Worker" madison_county_doc_puller/parallel_staged_download.log | tail -20
```

## Interrupting & Resuming

### Safe Interruption

Press `Ctrl+C` to stop gracefully:
- Current downloads complete
- Statistics saved
- Database updated
- No data corruption

### Resume Download

Just run the same command again:
```bash
./download_mid_filtered_documents.sh --workers 5
```

The system automatically:
- Skips completed documents
- Resets stale in-progress records
- Continues from where it left off

## Troubleshooting

### Problem: "GOOGLE_APPLICATION_CREDENTIALS not set"

```bash
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/credentials.json
```

### Problem: "Database connection failed"

```bash
# Load database credentials
source index_database/.db_credentials

# Test connection
PGPASSWORD="$DB_PASSWORD" psql -h 127.0.0.1 -p 5432 -U "$DB_USER" -d madison_county_index -c "\q"
```

### Problem: "ModuleNotFoundError"

```bash
pip install psycopg2-binary google-cloud-storage tqdm
```

### Problem: Workers timing out or failing

```bash
# Reduce worker count
./download_mid_filtered_documents.sh --workers 3

# Check server response times
# View recent errors in log
tail -100 madison_county_doc_puller/parallel_staged_download.log | grep -i error
```

## Files Created

### New Files

1. **`download_mid_filtered_documents.sh`** - Main shell script launcher
2. **`madison_county_doc_puller/parallel_staged_downloader.py`** - Parallel download engine
3. **`madison_county_doc_puller/PARALLEL_DOWNLOAD_README.md`** - Comprehensive documentation

### Modified Files

1. **`madison_county_doc_puller/download_queue_manager.py`** - Added `stage-mid-filtered` configuration and document type filtering

### Key Changes

**download_queue_manager.py:**
- Added new stage: `stage-mid-filtered`
- Configured for Books 238-3971
- Filters for 57 specific document types
- Updated `_build_filter_where_clause()` to handle document type filtering

## Configuration Options

### Worker Count

```bash
# Conservative (good for initial run)
--workers 3

# Balanced (recommended)
--workers 5

# Aggressive (maximum speed)
--workers 10
```

### Rate Limiting

Edit `madison_county_doc_puller/parallel_staged_downloader.py`:

```python
# Line 54
RATE_LIMIT_DELAY = 0.5  # Current: 500ms between requests

# More conservative (slower, safer)
RATE_LIMIT_DELAY = 1.0  # 1 second

# More aggressive (faster, riskier)
RATE_LIMIT_DELAY = 0.3  # 300ms
```

## Document Type Filtering

### Current Filter (57 types)

The stage filters documents by `instrument_type_parsed` column matching your specified list.

### To Add/Remove Types

Edit `madison_county_doc_puller/download_queue_manager.py`, line 133-148:

```python
'document_types': [
    'DEED',
    'YOUR_NEW_TYPE',  # Add new types here
    # Comment out or remove unwanted types
]
```

## Storage Organization

Documents are uploaded to GCS in this structure:

```
gs://madison-county-title-plant/documents/
â”œâ”€â”€ mid-early/           # Books 238-999
â”‚   â”œâ”€â”€ deed/
â”‚   â”‚   â””â”€â”€ 0238-0001.pdf
â”‚   â”œâ”€â”€ easement/
â”‚   â””â”€â”€ ...
â””â”€â”€ mid-recent/          # Books 1000-3971
    â”œâ”€â”€ deed/
    â”œâ”€â”€ trust-agreement/
    â””â”€â”€ ...
```

## Cost Estimate

### Storage (Google Cloud)

- **200,000 documents** Ã— 2 MB avg = **400 GB**
- After optimization (66.8% compression) = **133 GB**
- **STANDARD storage**: $3.40/month (first 30 days)
- **NEARLINE storage**: $1.33/month (after lifecycle transition)

### Compute Time

- **5 workers**: ~45 hours = $1.50-2.00 (if using cloud VM)
- **10 workers**: ~27 hours = $1.00-1.50 (if using cloud VM)

**Total First Month**: ~$5-10

## Performance Tips

### 1. Start Small

```bash
# Test with 3 workers first
./download_mid_filtered_documents.sh --workers 3
```

Monitor for 30 minutes:
- Check error rates
- Watch server response
- Verify GCS uploads

### 2. Scale Up

If stable, increase workers:
```bash
# Increase to 5 workers
./download_mid_filtered_documents.sh --workers 5

# If still stable, try 10
./download_mid_filtered_documents.sh --workers 10
```

### 3. Monitor Throughout

Watch these metrics:
- Success rate should stay >95%
- Mismatch rate 5-15% is expected
- Docs/hour should be stable
- Error types should be consistent

### 4. Optimize If Needed

If seeing issues:
- **High errors**: Reduce workers or increase rate limit
- **Slow uploads**: Check network, GCS region
- **Memory issues**: Reduce worker count
- **Database errors**: Check connection pool size

## Next Steps After Completion

### 1. Verify Results

```bash
# Check statistics
PGPASSWORD="$DB_PASSWORD" psql -h 127.0.0.1 -p 5432 -U "$DB_USER" -d madison_county_index -c "
SELECT
    COUNT(*) as total,
    COUNT(*) FILTER (WHERE download_status = 'completed') as completed,
    COUNT(*) FILTER (WHERE download_status = 'failed') as failed,
    ROUND(COUNT(*) FILTER (WHERE download_status = 'completed') * 100.0 / COUNT(*), 1) as pct_complete
FROM index_documents
WHERE book >= 238 AND book < 3972
  AND instrument_type_parsed IN (...);  -- Your document types
"
```

### 2. Handle Failed Downloads

```bash
# Retry failed documents (automatically uses retry stage)
cd madison_county_doc_puller
python3 parallel_staged_downloader.py --stage stage-4-retry --workers 3
```

### 3. Validate GCS Uploads

```bash
# Count uploaded files
gsutil ls -r gs://madison-county-title-plant/documents/mid-*/ | wc -l

# Check total size
gsutil du -sh gs://madison-county-title-plant/documents/mid-*/
```

### 4. Generate Report

Create a completion report:
- Total documents processed
- Success rate
- Document type breakdown
- Storage statistics
- Download duration
- Cost summary

## Support & Documentation

- **Parallel System**: `madison_county_doc_puller/PARALLEL_DOWNLOAD_README.md`
- **Staged System**: `madison_county_doc_puller/STAGED_DOWNLOAD_README.md`
- **Integration Guide**: `madison_county_doc_puller/STAGED_DOWNLOADER_INTEGRATION.md`
- **This Guide**: `QUICK_START_MID_FILTERED.md`

## Summary

You now have a **parallel download system** that:

âœ… Filters MID portal (Books 238-3971) to 57 specific document types
âœ… Uses 5-10 worker threads for concurrent downloads
âœ… Achieves 5-8x performance improvement over sequential
âœ… Handles ~200K documents in 1-2 days instead of 9 days
âœ… Includes automatic retry, error handling, and resumability
âœ… Optimizes PDFs for 66.8% storage savings
âœ… Uploads to organized GCS structure
âœ… Tracks progress in database with validation

**Ready to start?**

```bash
./download_mid_filtered_documents.sh --workers 5
```

ðŸš€ Happy downloading!
